{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422897fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Kode Lengkap: Prediksi Hidrostatik - Solusi XGBoost Tuned (GPU Enabled)\n",
    "\n",
    "Menggabungkan semua fase:\n",
    "1. Pemuatan Data & Koreksi Awal\n",
    "2. Preprocessing & Feature Engineering\n",
    "3. Tuning XGBoost dengan Optuna (Menggunakan GPU)\n",
    "4. Pelatihan Model XGBoost Final (GPU)\n",
    "5. Pembuatan File Submission\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.model_selection import KFold, train_test_split # train_test_split hanya untuk debug jika perlu\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# --- 1. Konfigurasi Dasar ---\n",
    "print(\"--- Konfigurasi ---\")\n",
    "TARGET_VARIABLE = 'hydrostatic_pressure'\n",
    "ID_COLUMN = 'measurement_id'\n",
    "TRAIN_FILE = 'train.csv'\n",
    "TEST_FILE = 'test.csv'\n",
    "SUBMISSION_FILE = 'sample_submission.csv'\n",
    "DB_FILENAME = 'optuna_studies.db' # File database Optuna\n",
    "FINAL_SUBMISSION_FILENAME_XGB = 'submission_xgb_gpu_tuned.csv'\n",
    "\n",
    "N_SPLITS = 5  # Jumlah fold untuk validasi dalam tuning\n",
    "RANDOM_SEED = 42 # Seed untuk reproduktifitas\n",
    "N_TRIALS_XGB_GPU = 50 # Jumlah trial Optuna (sesuaikan)\n",
    "OPTUNA_TIMEOUT = 600 # Batas waktu Optuna dalam detik (opsional, misal 10 menit)\n",
    "\n",
    "print(f\"Target: {TARGET_VARIABLE}\")\n",
    "print(f\"ID Column: {ID_COLUMN}\")\n",
    "print(f\"CV Folds: {N_SPLITS}\")\n",
    "print(f\"Optuna Trials: {N_TRIALS_XGB_GPU}\")\n",
    "print(f\"Random Seed: {RANDOM_SEED}\")\n",
    "print(f\"XGBoost Version: {xgb.__version__}\")\n",
    "\n",
    "# --- 2. Pemuatan Data & Koreksi Awal ---\n",
    "print(\"\\n--- Memuat Data ---\")\n",
    "try:\n",
    "    train_df_orig = pd.read_csv(TRAIN_FILE)\n",
    "    test_df_orig = pd.read_csv(TEST_FILE)\n",
    "    sample_submission_df = pd.read_csv(SUBMISSION_FILE)\n",
    "    print(f\"Train: {train_df_orig.shape}, Test: {test_df_orig.shape}, Sample Sub: {sample_submission_df.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File tidak ditemukan - {e}\")\n",
    "    exit()\n",
    "\n",
    "# Simpan ID test\n",
    "test_ids = test_df_orig[ID_COLUMN].copy()\n",
    "\n",
    "# Hapus kolom yang hanya ada di test\n",
    "cols_only_in_test = set(test_df_orig.columns) - set(train_df_orig.columns)\n",
    "if cols_only_in_test:\n",
    "    print(f\"Menghapus kolom hanya di test: {cols_only_in_test}\")\n",
    "    test_df_orig = test_df_orig.drop(columns=list(cols_only_in_test))\n",
    "\n",
    "# --- 3. Preprocessing & Feature Engineering ---\n",
    "print(\"\\n--- Preprocessing & Feature Engineering ---\")\n",
    "\n",
    "# 3.1 Pisahkan Target & Gabungkan Fitur\n",
    "y_train_full = train_df_orig[TARGET_VARIABLE].copy()\n",
    "train_ids = train_df_orig[ID_COLUMN].copy()\n",
    "train_features = train_df_orig.drop(columns=[TARGET_VARIABLE, ID_COLUMN])\n",
    "test_features = test_df_orig.drop(columns=[ID_COLUMN])\n",
    "ntrain = train_features.shape[0]\n",
    "all_features = pd.concat((train_features, test_features), ignore_index=True)\n",
    "print(f\"Data gabungan awal: {all_features.shape}\")\n",
    "\n",
    "# 3.2 Pembersihan Tipe Data Object (Koma Desimal)\n",
    "print(\"Membersihkan tipe data object (koma desimal)...\")\n",
    "object_cols = all_features.select_dtypes(include='object').columns.tolist()\n",
    "time_col = 'depth_reading_time'\n",
    "if time_col in object_cols: object_cols.remove(time_col)\n",
    "converted_cols = []\n",
    "for col in object_cols:\n",
    "    try:\n",
    "        if not all_features[col].isnull().all():\n",
    "            all_features[col] = all_features[col].str.replace(' ', '', regex=False).str.replace(',', '.', regex=False)\n",
    "            all_features[col] = pd.to_numeric(all_features[col])\n",
    "            converted_cols.append(col)\n",
    "    except Exception as e: print(f\"Warning: Gagal konversi kolom '{col}': {e}\")\n",
    "print(f\"Kolom objek dikonversi ke numerik: {len(converted_cols)}\")\n",
    "\n",
    "# 3.3 Parsing Waktu\n",
    "print(\"Memparsing fitur waktu...\")\n",
    "try:\n",
    "    all_features[time_col] = pd.to_datetime(all_features[time_col])\n",
    "    all_features['time_year'] = all_features[time_col].dt.year\n",
    "    all_features['time_month'] = all_features[time_col].dt.month\n",
    "    all_features['time_day'] = all_features[time_col].dt.day\n",
    "    all_features['time_dayofweek'] = all_features[time_col].dt.dayofweek\n",
    "    all_features['time_dayofyear'] = all_features[time_col].dt.dayofyear\n",
    "    all_features['time_hour'] = all_features[time_col].dt.hour\n",
    "    all_features['time_hour_sin'] = np.sin(2 * np.pi * all_features['time_hour']/24.0)\n",
    "    all_features['time_hour_cos'] = np.cos(2 * np.pi * all_features['time_hour']/24.0)\n",
    "    all_features['time_month_sin'] = np.sin(2 * np.pi * all_features['time_month']/12.0)\n",
    "    all_features['time_month_cos'] = np.cos(2 * np.pi * all_features['time_month']/12.0)\n",
    "    all_features = all_features.drop(columns=[time_col])\n",
    "    print(\"Fitur waktu berhasil diproses.\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Gagal parsing waktu '{time_col}': {e}\")\n",
    "\n",
    "# 3.4 Hapus Kolom Missing Tinggi (>50%)\n",
    "print(\"Menghapus kolom dengan >50% missing...\")\n",
    "cols_to_drop_high_missing = [\n",
    "    'aragonite_saturation_state', 'pH', 'dissolved_inorganic_carbon (µmol kg-1)',\n",
    "    'partial_pressure_CO2 (µatm)', 'water_temperature_50m'\n",
    "]\n",
    "existing_cols_to_drop = [col for col in cols_to_drop_high_missing if col in all_features.columns]\n",
    "if existing_cols_to_drop:\n",
    "    all_features = all_features.drop(columns=existing_cols_to_drop)\n",
    "    print(f\"Kolom dihapus: {existing_cols_to_drop}\")\n",
    "\n",
    "# 3.5 Hapus Sisa Kolom Non-Numerik\n",
    "non_numeric_cols = all_features.select_dtypes(exclude=np.number).columns\n",
    "if not non_numeric_cols.empty:\n",
    "    print(f\"Menghapus sisa kolom non-numerik: {non_numeric_cols.tolist()}\")\n",
    "    all_features = all_features.drop(columns=non_numeric_cols)\n",
    "\n",
    "print(f\"Bentuk data fitur akhir: {all_features.shape}\")\n",
    "\n",
    "# 3.6 Memisahkan Data Final\n",
    "X = all_features.iloc[:ntrain].copy()\n",
    "X_test = all_features.iloc[ntrain:].copy()\n",
    "y = y_train_full.copy()\n",
    "print(f\"Ukuran final - X: {X.shape}, y: {y.shape}, X_test: {X_test.shape}\")\n",
    "\n",
    "# --- 4. Tuning Hyperparameter XGBoost dengan Optuna (GPU) ---\n",
    "\n",
    "# 4.1 Fungsi Objective\n",
    "def objective_xgb_gpu(trial):\n",
    "    xgb_params = {\n",
    "        'objective': 'reg:squarederror', 'eval_metric': 'rmse',\n",
    "        'device': 'cuda', # Aktifkan GPU\n",
    "        'eta': trial.suggest_float('eta', 0.01, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 100),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n",
    "        'seed': RANDOM_SEED, 'nthread': -1, 'tree_method': 'hist'\n",
    "    }\n",
    "    n_estimators_xgb = trial.suggest_int('n_estimators', 500, 3000, step=100)\n",
    "    early_stopping_rounds_xgb = 50\n",
    "\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
    "    fold_scores = []\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_fold, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        model = xgb.XGBRegressor(**xgb_params, n_estimators=n_estimators_xgb)\n",
    "        try:\n",
    "            model.fit(X_train, y_train_fold,\n",
    "                      eval_set=[(X_val, y_val)],\n",
    "                      early_stopping_rounds=early_stopping_rounds_xgb,\n",
    "                      verbose=False)\n",
    "        except Exception as e:\n",
    "             print(f\"Error saat fit di fold {fold+1}: {e}. Mengembalikan nilai penalti.\")\n",
    "             return float('inf') # Penalti agar Optuna tidak memilih param ini\n",
    "        val_preds = model.predict(X_val)\n",
    "        fold_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "        fold_scores.append(fold_rmse)\n",
    "        trial.report(fold_rmse, fold)\n",
    "        if trial.should_prune(): raise optuna.TrialPruned()\n",
    "    return np.mean(fold_scores)\n",
    "\n",
    "# 4.2 Setup & Run Optuna Study\n",
    "STUDY_NAME_XGB_GPU = 'xgb_gpu_hydrostatic_tuning_final' # Nama studi\n",
    "try:\n",
    "    study_xgb_gpu = optuna.load_study(study_name=STUDY_NAME_XGB_GPU, storage=f'sqlite:///{DB_FILENAME}')\n",
    "    print(f\"Memuat studi Optuna XGBoost GPU '{STUDY_NAME_XGB_GPU}'\")\n",
    "    remaining_trials = max(0, N_TRIALS_XGB_GPU - len(study_xgb_gpu.trials))\n",
    "    if remaining_trials == 0: print(\"Jumlah trials sudah tercapai.\")\n",
    "    else: print(f\"Akan menjalankan {remaining_trials} trial tambahan.\")\n",
    "    N_TRIALS_TO_RUN = remaining_trials\n",
    "except KeyError:\n",
    "    print(f\"Membuat studi Optuna XGBoost GPU baru '{STUDY_NAME_XGB_GPU}'\")\n",
    "    study_xgb_gpu = optuna.create_study(direction='minimize', study_name=STUDY_NAME_XGB_GPU,\n",
    "                                        storage=f'sqlite:///{DB_FILENAME}', load_if_exists=True)\n",
    "    N_TRIALS_TO_RUN = N_TRIALS_XGB_GPU\n",
    "\n",
    "if N_TRIALS_TO_RUN > 0:\n",
    "    print(f\"\\nMemulai optimasi XGBoost GPU dengan {N_TRIALS_TO_RUN} trials...\")\n",
    "    start_opt_time = time.time()\n",
    "    study_xgb_gpu.optimize(objective_xgb_gpu, n_trials=N_TRIALS_TO_RUN, timeout=OPTUNA_TIMEOUT)\n",
    "    end_opt_time = time.time()\n",
    "    print(f\"Optimasi GPU selesai dalam {end_opt_time - start_opt_time:.2f} detik.\")\n",
    "\n",
    "# 4.3 Tampilkan Hasil Tuning XGBoost\n",
    "print(\"\\n--- Hasil Tuning Optuna XGBoost (GPU) ---\")\n",
    "best_xgb_gpu_params = None\n",
    "best_xgb_gpu_rmse = float('inf')\n",
    "if len(study_xgb_gpu.trials) > 0:\n",
    "    completed_trials = [t for t in study_xgb_gpu.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    if completed_trials:\n",
    "        best_trial_xgb_gpu = study_xgb_gpu.best_trial\n",
    "        best_xgb_gpu_rmse = best_trial_xgb_gpu.value\n",
    "        print(f\"Trial XGBoost GPU terbaik:\")\n",
    "        print(f\"  Value (Min RMSE): {best_xgb_gpu_rmse:.6f}\")\n",
    "        print(f\"  Params: \")\n",
    "        for key, value in best_trial_xgb_gpu.params.items(): print(f\"    {key}: {value}\")\n",
    "        # Simpan parameter terbaik\n",
    "        best_xgb_gpu_params = { 'objective': 'reg:squarederror', 'eval_metric': 'rmse',\n",
    "                                'seed': RANDOM_SEED, 'nthread': -1, 'tree_method': 'hist',\n",
    "                                'device': 'cuda' } # Penting: tambahkan device cuda\n",
    "        best_xgb_gpu_params.update(best_trial_xgb_gpu.params)\n",
    "        print(\"\\nParameter XGBoost GPU terbaik disimpan.\")\n",
    "    else: print(\"\\nTidak ada trial Optuna GPU yang berhasil COMPLETE.\")\n",
    "else: print(\"\\nTidak ada trial Optuna GPU yang dijalankan.\")\n",
    "\n",
    "\n",
    "# --- 5. Pelatihan Model Final & Submission ---\n",
    "\n",
    "# Pilih parameter terbaik (antara LGBM tuned atau XGB tuned jika ada)\n",
    "# Asumsi kita punya best_lgbm_params dari tuning sebelumnya dan skornya\n",
    "try:\n",
    "    # Ambil skor LGBM terbaik dari trial sebelumnya (jika ada)\n",
    "    # Anda mungkin perlu memuat studi LGBM jika tidak ada di memori\n",
    "    study_lgbm = optuna.load_study(study_name='lgbm_hydrostatic_tuning', storage=f'sqlite:///{DB_FILENAME}') # Ganti nama jika berbeda\n",
    "    best_lgbm_rmse = study_lgbm.best_trial.value\n",
    "    print(f\"\\nSkor CV LGBM Terbaik (dari DB): {best_lgbm_rmse:.6f}\")\n",
    "\n",
    "    # Bandingkan\n",
    "    if best_xgb_gpu_params is not None and best_xgb_gpu_rmse < best_lgbm_rmse:\n",
    "        print(\"\\nXGBoost (GPU) Tuned lebih baik. Menggunakan XGBoost untuk model final.\")\n",
    "        final_model_params = best_xgb_gpu_params\n",
    "        final_model = xgb.XGBRegressor(**final_model_params)\n",
    "        model_type = \"XGBoost_GPU\"\n",
    "    else:\n",
    "        print(\"\\nLGBM Tuned lebih baik atau XGBoost gagal. Menggunakan LGBM untuk model final.\")\n",
    "        # Pastikan best_lgbm_params ada dari proses sebelumnya\n",
    "        if 'best_lgbm_params' not in locals():\n",
    "            print(\"ERROR: Variabel 'best_lgbm_params' tidak ditemukan!\")\n",
    "            # Muat ulang dari studi LGBM jika perlu\n",
    "            best_lgbm_params_from_study = { 'objective': 'regression_l2', 'metric': 'rmse', ... } # Parameter dasar\n",
    "            best_lgbm_params_from_study.update(study_lgbm.best_trial.params)\n",
    "            best_lgbm_params = best_lgbm_params_from_study\n",
    "            print(\"Parameter LGBM dimuat ulang dari studi.\")\n",
    "\n",
    "        final_model_params = best_lgbm_params\n",
    "        final_model = lgb.LGBMRegressor(**final_model_params)\n",
    "        model_type = \"LightGBM\"\n",
    "\n",
    "except KeyError:\n",
    "    print(\"\\nStudi LGBM tidak ditemukan di DB. Menggunakan hasil XGBoost (GPU) jika ada.\")\n",
    "    if best_xgb_gpu_params is not None:\n",
    "        final_model_params = best_xgb_gpu_params\n",
    "        final_model = xgb.XGBRegressor(**final_model_params)\n",
    "        model_type = \"XGBoost_GPU\"\n",
    "    else:\n",
    "        print(\"ERROR: Tidak ada parameter model terbaik yang bisa digunakan!\")\n",
    "        final_model = None\n",
    "        model_type = \"None\"\n",
    "except NameError:\n",
    "     print(\"\\nVariabel best_lgbm_params tidak ditemukan. Menggunakan hasil XGBoost (GPU) jika ada.\")\n",
    "     if best_xgb_gpu_params is not None:\n",
    "        final_model_params = best_xgb_gpu_params\n",
    "        final_model = xgb.XGBRegressor(**final_model_params)\n",
    "        model_type = \"XGBoost_GPU\"\n",
    "     else:\n",
    "        print(\"ERROR: Tidak ada parameter model terbaik yang bisa digunakan!\")\n",
    "        final_model = None\n",
    "        model_type = \"None\"\n",
    "\n",
    "\n",
    "# Latih model final jika parameter terpilih\n",
    "if final_model is not None:\n",
    "    print(f\"\\n--- Melatih Model Final ({model_type}) pada Seluruh Data Training ---\")\n",
    "    start_time_final_train = time.time()\n",
    "    # Latih pada X dan y lengkap\n",
    "    final_model.fit(X, y) # Tanpa early stopping untuk training final\n",
    "    end_time_final_train = time.time()\n",
    "    print(f\"Pelatihan model final selesai dalam {end_time_final_train - start_time_final_train:.2f} detik.\")\n",
    "\n",
    "    # Buat prediksi pada data test\n",
    "    print(\"\\nMembuat prediksi pada data test...\")\n",
    "    if not X_test.empty:\n",
    "        final_test_predictions = final_model.predict(X_test)\n",
    "\n",
    "        # Buat DataFrame submission\n",
    "        print(\"Membuat file submission...\")\n",
    "        submission_df = pd.DataFrame({\n",
    "            ID_COLUMN: test_ids,\n",
    "            TARGET_VARIABLE: final_test_predictions\n",
    "        })\n",
    "\n",
    "        # Simpan ke file CSV\n",
    "        submission_df.to_csv(FINAL_SUBMISSION_FILENAME_XGB, index=False)\n",
    "        print(f\"\\nFile submission '{FINAL_SUBMISSION_FILENAME_XGB}' telah berhasil dibuat.\")\n",
    "        print(\"Contoh isi file submission:\")\n",
    "        print(submission_df.head())\n",
    "    else:\n",
    "        print(\"\\nData test (X_test) kosong, submission tidak dibuat.\")\n",
    "else:\n",
    "    print(\"\\nTidak dapat melatih model final karena tidak ada parameter terbaik yang valid.\")\n",
    "\n",
    "print(\"\\n--- Proses Selesai ---\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
